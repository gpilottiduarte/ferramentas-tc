<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sobre a ferramenta de análise de cobertura da documentação - Segura - 2025</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
    <style>
        /* Reutilizando os estilos básicos do container e corpo do index.html */
        body {
            font-family: 'Roboto', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            padding: 40px;
            max-width: 900px;
            width: 100%;
            animation: fadeInUp 0.6s ease-out;
            color: #2d3748; /* Cor do texto padrão */
            line-height: 1.6;
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(30px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        h1 {
            color: #2d3748;
            font-size: 2.5rem;
            margin-bottom: 10px;
            text-align: center;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        h2, h3 {
            color: #2d3748;
            margin-top: 1.5em;
            margin-bottom: 0.8em;
            font-weight: 700;
        }

        h2 { font-size: 1.8rem; }
        h3 { font-size: 1.4rem; }

        p {
            margin-bottom: 1em;
        }

        ul, ol {
            margin-bottom: 1em;
            margin-left: 20px;
        }

        ul li {
            list-style-type: disc;
            margin-bottom: 0.5em;
        }

        ol li {
            list-style-type: decimal;
            margin-bottom: 0.5em;
        }

        strong {
            font-weight: bold;
        }

        .highlight-box {
            background: #e6fffa;
            border-left: 5px solid #38b2ac;
            padding: 15px 20px;
            margin-bottom: 1.5em;
            border-radius: 8px;
            color: #2d3748;
        }

        .highlight-box ul {
            margin-top: 10px;
            margin-bottom: 0;
        }

        a {
            color: #667eea;
            text-decoration: none;
            font-weight: bold;
            transition: color 0.3s ease;
        }

        a:hover {
            color: #764ba2;
            text-decoration: underline;
        }

        center a {
            font-size: 1.2rem;
            padding: 10px 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 12px;
            display: inline-block;
            margin-top: 20px;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        center a:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 20px rgba(0, 0, 0, 0.3);
            text-decoration: none;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
                margin: 10px;
            }
            h1 {
                font-size: 2rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Sobre a ferramenta de análise de cobertura da documentação - Segura - 2025</h1>

        <p>Este aplicativo foi projetado para ajudar você a identificar lacunas e oportunidades de melhoria na sua documentação técnica. Ele utiliza o poder da inteligência artificial para analisar o conteúdo existente e sugerir onde e como a cobertura pode ser expandida.</p>

        <h2>Como funciona? O fluxo de análise detalhado</h2>
        <p>A ferramenta opera em um fluxo de trabalho dividido em etapas, garantindo que sua documentação seja processada e analisada de forma eficiente pela Inteligência Artificial:</p>
        <ol>
            <li>
                <h3>1. Preparação da documentação (offline):</h3>
                <p>Esta é a etapa inicial, feita uma única vez ou sempre que sua documentação for atualizada. Ela ocorre **antes** de você usar o aplicativo web:</p>
                <ul>
                    <li>
                        <strong>Extração e limpeza:</strong> Seus documentos de origem (geralmente em formato Markdown) são lidos por um script Python (<strong>`extract_data_from_markdown.py`</strong>). Este script é responsável por:
                        <ul>
                            <li>Identificar e extrair o texto principal de cada documento.</li>
                            <li>Limpar o conteúdo, removendo elementos desnecessários como cabeçalhos, rodapés ou códigos de formatação específicos que não contribuam para o significado do texto.</li>
                            <li>Extrair metadados importantes, como o <strong>título</strong> e o <strong>slug</strong> (um identificador único e amigável para o URL) de cada documento.</li>
                            <li>O resultado é salvo em um arquivo intermediário, geralmente <strong>`raw_docs.json`</strong>, que contém o conteúdo limpo e os metadados.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Geração de embeddings:</strong> Em seguida, outro script Python (<strong>`generate_embeddings.py`</strong>) entra em ação. Ele lê o <strong>`raw_docs.json`</strong> e interage com a API do Google Gemini:
                        <ul>
                            <li>Para cada trecho de texto extraído, ele envia o conteúdo para o modelo de IA do Google Gemini (especificamente o modelo <strong>`embedding-001`</strong>).</li>
                            <li>Este modelo retorna um <strong>"embedding"</strong>: uma representação numérica do texto em um espaço multidimensional. Pense nisso como um vetor de números que captura o "significado" ou a "ideia" do seu documento. Documentos com significados semelhantes terão embeddings (vetores) mais próximos nesse espaço.</li>
                            <li>O objetivo é transformar o texto complexo em um formato que a máquina pode entender e comparar de forma eficiente.</li>
                            <li>Todos os documentos, agora enriquecidos com seus respectivos embeddings, são salvos no arquivo <strong>`processed_docs.json`</strong>. Este é o arquivo principal que a ferramenta web utilizará.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>
                <h3>2. Análise em tempo real (a aplicação web):</h3>
                <p>Esta etapa ocorre no navegador, quando você interage com a ferramenta:</p>
                <ul>
                    <li>
                        <strong>Carregamento da base de dados:</strong> Ao abrir a página `index.html`, o JavaScript da ferramenta carrega automaticamente o arquivo <strong>`processed_docs.json`</strong> na memória do seu navegador. Isso permite que a ferramenta acesse rapidamente todos os embeddings da sua documentação.
                    </li>
                    <li>
                        <strong>Consulta do usuário:</strong> Você digita uma pergunta, um tópico ou cola um trecho de texto na caixa de entrada.
                    </li>
                    <li>
                        <strong>Geração de embedding da consulta:</strong> A sua entrada é enviada para o mesmo modelo de embedding do Google Gemini (<strong>`embedding-001`</strong>) para gerar um embedding correspondente.
                    </li>
                    <li>
                        <strong>Busca por similaridade:</strong> O embedding da sua consulta é então comparado com os embeddings de <strong>todos</strong> os documentos carregados do `processed_docs.json`. Para isso, é usada a técnica de **Similaridade de Cosseno**.
                        <ul>
                            <li>Os documentos com os embeddings mais "próximos" (ou seja, com maior similaridade de cosseno) são identificados como os mais relevantes para a sua consulta.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Geração de sugestões pela IA:</strong> Os documentos mais relevantes (normalmente os 3 a 5 com maior similaridade) são empacotados junto com a sua pergunta original e enviados para um modelo de linguagem grande e generativo do Google Gemini (o <strong>`gemini-1.5-pro-latest`</strong>).
                        <ul>
                            <li>Este modelo de IA analisa o contexto fornecido (seus documentos relevantes) em relação à sua pergunta.</li>
                            <li>Ele então gera uma resposta detalhada, identificando lacunas na documentação existente, sugerindo novos tópicos, melhorias ou expansões para os documentos atuais.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Exibição dos resultados:</strong> A resposta do modelo Gemini, que geralmente vem em formato Markdown, é convertida para HTML pelo navegador (usando a biblioteca `marked.js`) e exibida de forma formatada na interface da ferramenta, juntamente com a lista de documentos que foram considerados mais relevantes.
                    </li>
                </ul>
            </li>
        </ol>

        <h2>Componentes e funções principais</h2>
        <p>Conheça os principais elementos que compõem esta solução e suas responsabilidades:</p>
        <ul>
            <li>
                <strong>`extract_data_from_markdown.py`</strong>:
                <p><strong>Função:</strong> Script Python responsável por ler seus arquivos Markdown (ou outros formatos de documento), extrair o conteúdo textual relevante e metadados como título e slug, e salvar esses dados de forma estruturada em um arquivo JSON (<strong>`raw_docs.json`</strong>).</p>
                <p><strong>Importância:</strong> É a primeira etapa do pipeline, garantindo que o texto bruto seja limpo e preparado para a próxima fase.</p>
            </li>
            <li>
                <strong>`generate_embeddings.py`</strong>:
                <p><strong>Função:</strong> Script Python que consome o `raw_docs.json`, interage com a API do Google Gemini para gerar embeddings de cada documento e, em seguida, armazena esses embeddings junto com os dados originais no arquivo <strong>`processed_docs.json`</strong>.</p>
                <p><strong>Importância:</strong> Transforma o texto em um formato numérico que permite à IA entender o significado e a similaridade entre documentos.</p>
            </li>
            <li>
                <strong>`processed_docs.json`</strong>:
                <p><strong>Função:</strong> O banco de dados da sua documentação. Este arquivo JSON contém todos os seus documentos, seus títulos, slugs, caminhos de arquivo e, crucialmente, os embeddings gerados.</p>
                <p><strong>Importância:</strong> É a base de conhecimento que a ferramenta web consulta para encontrar documentos relevantes.</p>
            </li>
            <li>
                <strong>`index.html` (com JavaScript)</strong>:
                <p><strong>Função:</strong> É a interface do usuário da ferramenta, que você acessa no navegador. Ele carrega o `processed_docs.json`, recebe sua consulta, gera seu embedding (chamando a API do Gemini), realiza a busca por similaridade e exibe as sugestões de melhoria geradas pelo Gemini.</p>
                <p><strong>Importância:</strong> É o ponto de interação do usuário com a ferramenta, orquestrando as chamadas de IA e a exibição dos resultados.</p>
            </li>
            <li>
                <strong>Google Gemini (`embedding-001`)</strong>:
                <p><strong>Função:</strong> Um modelo de Inteligência Artificial do Google, especializado em criar embeddings. Ele converte texto em vetores numéricos de alta dimensão, que representam o significado semântico do texto.</p>
                <p><strong>Importância:</strong> Essencial para a função de busca por similaridade, permitindo que a ferramenta encontre documentos "semelhantes" à sua consulta.</p>
            </li>
            <li>
                <strong>Google Gemini (`gemini-1.5-pro-latest`)</strong>:
                <p><strong>Função:</strong> Um modelo de linguagem generativo avançado do Google. Ele é capaz de entender contextos complexos, raciocinar e gerar texto coerente e relevante com base nas informações fornecidas.</p>
                <p><strong>Importância:</strong> É o "cérebro" da ferramenta que analisa os documentos relevantes e sua consulta para gerar as sugestões de melhoria da documentação.</p>
            </li>
        </ul>

        <h2>Termos chave</h2>
        <p>Para entender melhor como esta ferramenta funciona, familiarize-se com alguns termos importantes:</p>
        <ul>
            <li>
                <strong>Embeddings (ou vetores de embeddings)</strong>:
                <p>São representações numéricas de textos (palavras, frases, documentos inteiros) em um espaço de alta dimensão. Pense em cada texto como um ponto nesse espaço. Textos com significados semelhantes estarão mais próximos uns dos outros. Isso permite que algoritmos matemáticos (como a similaridade de cosseno) comparem e encontrem relações entre textos.</p>
            </li>
            <li>
                <strong>Similaridade de cosseno</strong>:
                <p>É uma métrica usada para medir o quão semelhantes são dois vetores (neste caso, embeddings), calculando o cosseno do ângulo entre eles.
                <ul>
                    <li>Um valor de <strong>1</strong> (ou 100%) indica que os vetores são idênticos em direção (altamente similares).</li>
                    <li>Um valor de <strong>0</strong> indica que são perpendiculares (sem relação).</li>
                    <li>Um valor de <strong>-1</strong> indica que são opostos (com significados muito diferentes).</li>
                </ul>
                Na prática, quanto maior a similaridade de cosseno, maior a relevância semântica entre sua consulta e um documento.</p>
            </li>
            <li>
                <strong>Modelos generativos (Large Language Models - LLMs)</strong>:
                <p>São modelos de Inteligência Artificial treinados em vastas quantidades de texto para entender, gerar e processar linguagem humana. Modelos como o Gemini 1.5 Pro podem realizar tarefas complexas como resumir, traduzir, responder perguntas e, no nosso caso, sugerir melhorias contextuais em documentos.</p>
            </li>
            <li>
                <strong>Slug</strong>:
                <p>É uma parte de um URL que identifica uma página específica de forma legível por humanos e por mecanismos de busca. Por exemplo, em `https://docs.senhasegura.io/v4/docs/jit-access`, `jit-access` é o slug. Ele ajuda a ferramenta a referenciar os documentos da sua documentação online.</p>
            </li>
            <li>
                <strong>API (Application Programming Interface)</strong>:
                <p>É um conjunto de regras e definições que permite que diferentes softwares se comuniquem entre si. No nosso caso, a ferramenta web usa a API do Google Gemini para enviar seu texto e receber os embeddings ou as sugestões de texto geradas pela IA.</p>
            </li>
        </ul>
        <h2>Considerações finais</h2>
        <p>Esta ferramenta visa melhorar a qualidade e a abrangência da  documentação técnica. Ao automatizar a análise e sugerir melhorias, ela permite que uma maior concentração no conteúdo, enquanto a IA cuida da identificação de lacunas e oportunidades de expansão.</p>

        <center><a href="index.html">Voltar para a análise de cobertura</a></center>
    </div>
</body>
</html>